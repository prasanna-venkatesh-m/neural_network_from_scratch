{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOn1r5UIPeu9qtAw7/c6nWo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasanna-venkatesh-m/neural_network_from_scratch/blob/main/neural_network_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "nzKd7T8NR2Qv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Position_Salaries.csv');\n",
        "df = df.drop(columns=['Position'])"
      ],
      "metadata": {
        "id": "qaUhoRgCOT-q"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['Level'].to_frame()\n",
        "y = df['Salary'].to_frame()"
      ],
      "metadata": {
        "id": "qPq_JmsUPdir"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_sc = StandardScaler()\n",
        "y_sc = StandardScaler()"
      ],
      "metadata": {
        "id": "_D0h73ZbaGSE"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_np = x_sc.fit_transform(X)  # converts DataFrame to numpy array\n",
        "y_np = y_sc.fit_transform(y)  # same for target"
      ],
      "metadata": {
        "id": "GvjN5a0DYTnK"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = 16\n",
        "W1 = np.random.rand(X.shape[1],layer1)\n",
        "b1 = np.random.rand(layer1,)\n",
        "\n",
        "layer2 = 1\n",
        "W2 = np.random.rand(layer1, layer2)\n",
        "b2 = np.random.rand(layer2,)\n",
        "\n",
        "epoch = 1000\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "UhvgnsztNwqg"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(X, W1, b1, W2, b2):\n",
        "\n",
        "  # Layer 1\n",
        "  Z1 = np.dot(X, W1) + b1 #X (m,n) W1(n,16) result(m,16)\n",
        "\n",
        "  # Layer 2\n",
        "  Z2 = np.dot(Z1, W2) + b2 #Z1(m,16) W2(16,1) result(m,1)\n",
        "\n",
        "  return Z1, Z2"
      ],
      "metadata": {
        "id": "ISMHWSRFSBHH"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y, y_pred):\n",
        "  return mean_squared_error(y, y_pred)"
      ],
      "metadata": {
        "id": "mEuCCdO5Nat2"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_pass(X,y, Z1, Z2, W2):\n",
        "  m = X.shape[0]\n",
        "\n",
        "  dZ2 = (2 / m) * (Z2 - y) #z2(m,1) y(m,1) result(m,1)\n",
        "  dW2 = np.dot(Z1.T, dZ2) #z1(n,16) dz2(m,1) so(16,n)*(m,1) result(16,1)\n",
        "  db2 = np.sum(dZ2, axis=0) #dz2 (m,1) result(1,)\n",
        "\n",
        "  dZ1 = np.dot(dZ2, W2.T) #dZ2(m,1) W2(16,1) so(m,1)*(1,16) result(m,16)\n",
        "  dW1 = np.dot(X.T, dZ1) #X(m,n) dz1(m,16) so(n,m)*(m,16) result(n,16)\n",
        "  db1 = np.sum(dZ1, axis=0) #dz1(m,16) result(16,)\n",
        "\n",
        "  return dW1, db1, dW2, db2"
      ],
      "metadata": {
        "id": "m1BtXhDoNkpM"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epoch):\n",
        "  Z1, Z2 = forward_pass(X_np, W1, b1, W2, b2)\n",
        "  loss = loss_function(y_np, Z2)\n",
        "\n",
        "  dw1, db1, dw2, db2 = backward_pass(X_np,y_np, Z1, Z2, W2)\n",
        "\n",
        "  W1 -= learning_rate * dw1\n",
        "  b1 -= learning_rate * db1\n",
        "  W2 -= learning_rate * dw2\n",
        "  b2 -= learning_rate * db2\n",
        "\n",
        "  print(f'Epoch: {i} Loss: {loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8WlabvBWp7T",
        "outputId": "a8d8a763-e6bf-4242-b762-969bd53638bf"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 25.91664040883607\n",
            "Epoch: 1 Loss: 13.615187352313644\n",
            "Epoch: 2 Loss: 7.876847158717737\n",
            "Epoch: 3 Loss: 4.8249662088668295\n",
            "Epoch: 4 Loss: 3.082155028504652\n",
            "Epoch: 5 Loss: 2.0441226123034886\n",
            "Epoch: 6 Loss: 1.4095060637200694\n",
            "Epoch: 7 Loss: 1.0149791648245268\n",
            "Epoch: 8 Loss: 0.7669976743451772\n",
            "Epoch: 9 Loss: 0.6099663580423903\n",
            "Epoch: 10 Loss: 0.5100132649330226\n",
            "Epoch: 11 Loss: 0.44615341492556987\n",
            "Epoch: 12 Loss: 0.4052374581620983\n",
            "Epoch: 13 Loss: 0.37896160783377264\n",
            "Epoch: 14 Loss: 0.36205359672757825\n",
            "Epoch: 15 Loss: 0.3511530326210536\n",
            "Epoch: 16 Loss: 0.3441120416929146\n",
            "Epoch: 17 Loss: 0.33955479182094184\n",
            "Epoch: 18 Loss: 0.3365984494308177\n",
            "Epoch: 19 Loss: 0.33467567504642365\n",
            "Epoch: 20 Loss: 0.3334213728035721\n",
            "Epoch: 21 Loss: 0.33260027518633595\n",
            "Epoch: 22 Loss: 0.3320605602053258\n",
            "Epoch: 23 Loss: 0.33170410212426477\n",
            "Epoch: 24 Loss: 0.3314673686315145\n",
            "Epoch: 25 Loss: 0.3313091416043881\n",
            "Epoch: 26 Loss: 0.3312026161705863\n",
            "Epoch: 27 Loss: 0.3311303117751131\n",
            "Epoch: 28 Loss: 0.3310807908848085\n",
            "Epoch: 29 Loss: 0.3310465406948153\n",
            "Epoch: 30 Loss: 0.3310226037517026\n",
            "Epoch: 31 Loss: 0.3310056913012581\n",
            "Epoch: 32 Loss: 0.3309936081132669\n",
            "Epoch: 33 Loss: 0.3309848785302366\n",
            "Epoch: 34 Loss: 0.33097850269731993\n",
            "Epoch: 35 Loss: 0.3309737971533719\n",
            "Epoch: 36 Loss: 0.3309702901990632\n",
            "Epoch: 37 Loss: 0.3309676529168609\n",
            "Epoch: 38 Loss: 0.3309656534606827\n",
            "Epoch: 39 Loss: 0.3309641265844638\n",
            "Epoch: 40 Loss: 0.33096295319010827\n",
            "Epoch: 41 Loss: 0.33096204649386457\n",
            "Epoch: 42 Loss: 0.33096134258844834\n",
            "Epoch: 43 Loss: 0.3309607939430891\n",
            "Epoch: 44 Loss: 0.3309603648812948\n",
            "Epoch: 45 Loss: 0.33096002840073624\n",
            "Epoch: 46 Loss: 0.33095976391210186\n",
            "Epoch: 47 Loss: 0.3309595556133349\n",
            "Epoch: 48 Loss: 0.33095939130776203\n",
            "Epoch: 49 Loss: 0.33095926153571875\n",
            "Epoch: 50 Loss: 0.3309591589300561\n",
            "Epoch: 51 Loss: 0.3309590777333179\n",
            "Epoch: 52 Loss: 0.3309590134329442\n",
            "Epoch: 53 Loss: 0.3309589624835423\n",
            "Epoch: 54 Loss: 0.33095892209402067\n",
            "Epoch: 55 Loss: 0.3309588900634826\n",
            "Epoch: 56 Loss: 0.3309588646540737\n",
            "Epoch: 57 Loss: 0.3309588444920387\n",
            "Epoch: 58 Loss: 0.3309588284904527\n",
            "Epoch: 59 Loss: 0.33095881578869546\n",
            "Epoch: 60 Loss: 0.3309588057049221\n",
            "Epoch: 61 Loss: 0.33095879769866\n",
            "Epoch: 62 Loss: 0.3309587913413263\n",
            "Epoch: 63 Loss: 0.33095878629295383\n",
            "Epoch: 64 Loss: 0.33095878228379677\n",
            "Epoch: 65 Loss: 0.3309587790997802\n",
            "Epoch: 66 Loss: 0.33095877657098227\n",
            "Epoch: 67 Loss: 0.3309587745625072\n",
            "Epoch: 68 Loss: 0.3309587729672534\n",
            "Epoch: 69 Loss: 0.33095877170017973\n",
            "Epoch: 70 Loss: 0.33095877069375534\n",
            "Epoch: 71 Loss: 0.33095876989435113\n",
            "Epoch: 72 Loss: 0.33095876925937656\n",
            "Epoch: 73 Loss: 0.3309587687550056\n",
            "Epoch: 74 Loss: 0.3309587683543723\n",
            "Epoch: 75 Loss: 0.3309587680361384\n",
            "Epoch: 76 Loss: 0.33095876778335553\n",
            "Epoch: 77 Loss: 0.3309587675825614\n",
            "Epoch: 78 Loss: 0.3309587674230633\n",
            "Epoch: 79 Loss: 0.3309587672963678\n",
            "Epoch: 80 Loss: 0.3309587671957285\n",
            "Epoch: 81 Loss: 0.3309587671157866\n",
            "Epoch: 82 Loss: 0.3309587670522852\n",
            "Epoch: 83 Loss: 0.3309587670018434\n",
            "Epoch: 84 Loss: 0.33095876696177506\n",
            "Epoch: 85 Loss: 0.33095876692994713\n",
            "Epoch: 86 Loss: 0.3309587669046647\n",
            "Epoch: 87 Loss: 0.33095876688458187\n",
            "Epoch: 88 Loss: 0.33095876686862913\n",
            "Epoch: 89 Loss: 0.330958766855957\n",
            "Epoch: 90 Loss: 0.330958766845891\n",
            "Epoch: 91 Loss: 0.3309587668378951\n",
            "Epoch: 92 Loss: 0.33095876683154357\n",
            "Epoch: 93 Loss: 0.33095876682649816\n",
            "Epoch: 94 Loss: 0.3309587668224905\n",
            "Epoch: 95 Loss: 0.33095876681930697\n",
            "Epoch: 96 Loss: 0.3309587668167781\n",
            "Epoch: 97 Loss: 0.3309587668147695\n",
            "Epoch: 98 Loss: 0.3309587668131737\n",
            "Epoch: 99 Loss: 0.33095876681190634\n",
            "Epoch: 100 Loss: 0.3309587668108995\n",
            "Epoch: 101 Loss: 0.3309587668100996\n",
            "Epoch: 102 Loss: 0.33095876680946434\n",
            "Epoch: 103 Loss: 0.33095876680895964\n",
            "Epoch: 104 Loss: 0.3309587668085589\n",
            "Epoch: 105 Loss: 0.3309587668082403\n",
            "Epoch: 106 Loss: 0.33095876680798736\n",
            "Epoch: 107 Loss: 0.3309587668077866\n",
            "Epoch: 108 Loss: 0.3309587668076268\n",
            "Epoch: 109 Loss: 0.33095876680750014\n",
            "Epoch: 110 Loss: 0.33095876680739944\n",
            "Epoch: 111 Loss: 0.3309587668073194\n",
            "Epoch: 112 Loss: 0.330958766807256\n",
            "Epoch: 113 Loss: 0.33095876680720543\n",
            "Epoch: 114 Loss: 0.33095876680716535\n",
            "Epoch: 115 Loss: 0.33095876680713354\n",
            "Epoch: 116 Loss: 0.3309587668071081\n",
            "Epoch: 117 Loss: 0.330958766807088\n",
            "Epoch: 118 Loss: 0.33095876680707215\n",
            "Epoch: 119 Loss: 0.3309587668070594\n",
            "Epoch: 120 Loss: 0.3309587668070493\n",
            "Epoch: 121 Loss: 0.3309587668070414\n",
            "Epoch: 122 Loss: 0.3309587668070349\n",
            "Epoch: 123 Loss: 0.3309587668070299\n",
            "Epoch: 124 Loss: 0.33095876680702585\n",
            "Epoch: 125 Loss: 0.3309587668070227\n",
            "Epoch: 126 Loss: 0.33095876680702024\n",
            "Epoch: 127 Loss: 0.33095876680701836\n",
            "Epoch: 128 Loss: 0.3309587668070164\n",
            "Epoch: 129 Loss: 0.3309587668070153\n",
            "Epoch: 130 Loss: 0.3309587668070143\n",
            "Epoch: 131 Loss: 0.33095876680701347\n",
            "Epoch: 132 Loss: 0.33095876680701297\n",
            "Epoch: 133 Loss: 0.3309587668070124\n",
            "Epoch: 134 Loss: 0.330958766807012\n",
            "Epoch: 135 Loss: 0.33095876680701164\n",
            "Epoch: 136 Loss: 0.3309587668070114\n",
            "Epoch: 137 Loss: 0.3309587668070112\n",
            "Epoch: 138 Loss: 0.3309587668070111\n",
            "Epoch: 139 Loss: 0.330958766807011\n",
            "Epoch: 140 Loss: 0.33095876680701086\n",
            "Epoch: 141 Loss: 0.33095876680701064\n",
            "Epoch: 142 Loss: 0.33095876680701075\n",
            "Epoch: 143 Loss: 0.33095876680701053\n",
            "Epoch: 144 Loss: 0.33095876680701064\n",
            "Epoch: 145 Loss: 0.33095876680701053\n",
            "Epoch: 146 Loss: 0.33095876680701053\n",
            "Epoch: 147 Loss: 0.33095876680701064\n",
            "Epoch: 148 Loss: 0.33095876680701053\n",
            "Epoch: 149 Loss: 0.3309587668070105\n",
            "Epoch: 150 Loss: 0.3309587668070105\n",
            "Epoch: 151 Loss: 0.33095876680701053\n",
            "Epoch: 152 Loss: 0.3309587668070104\n",
            "Epoch: 153 Loss: 0.3309587668070105\n",
            "Epoch: 154 Loss: 0.3309587668070104\n",
            "Epoch: 155 Loss: 0.3309587668070105\n",
            "Epoch: 156 Loss: 0.33095876680701036\n",
            "Epoch: 157 Loss: 0.33095876680701053\n",
            "Epoch: 158 Loss: 0.3309587668070103\n",
            "Epoch: 159 Loss: 0.33095876680701036\n",
            "Epoch: 160 Loss: 0.3309587668070104\n",
            "Epoch: 161 Loss: 0.33095876680701036\n",
            "Epoch: 162 Loss: 0.33095876680701036\n",
            "Epoch: 163 Loss: 0.33095876680701053\n",
            "Epoch: 164 Loss: 0.3309587668070105\n",
            "Epoch: 165 Loss: 0.3309587668070105\n",
            "Epoch: 166 Loss: 0.3309587668070105\n",
            "Epoch: 167 Loss: 0.33095876680701053\n",
            "Epoch: 168 Loss: 0.3309587668070105\n",
            "Epoch: 169 Loss: 0.33095876680701053\n",
            "Epoch: 170 Loss: 0.3309587668070105\n",
            "Epoch: 171 Loss: 0.33095876680701025\n",
            "Epoch: 172 Loss: 0.3309587668070105\n",
            "Epoch: 173 Loss: 0.3309587668070104\n",
            "Epoch: 174 Loss: 0.33095876680701053\n",
            "Epoch: 175 Loss: 0.33095876680701036\n",
            "Epoch: 176 Loss: 0.3309587668070105\n",
            "Epoch: 177 Loss: 0.3309587668070104\n",
            "Epoch: 178 Loss: 0.3309587668070104\n",
            "Epoch: 179 Loss: 0.3309587668070105\n",
            "Epoch: 180 Loss: 0.3309587668070105\n",
            "Epoch: 181 Loss: 0.3309587668070105\n",
            "Epoch: 182 Loss: 0.33095876680701036\n",
            "Epoch: 183 Loss: 0.33095876680701036\n",
            "Epoch: 184 Loss: 0.3309587668070104\n",
            "Epoch: 185 Loss: 0.3309587668070104\n",
            "Epoch: 186 Loss: 0.33095876680701036\n",
            "Epoch: 187 Loss: 0.33095876680701036\n",
            "Epoch: 188 Loss: 0.33095876680701036\n",
            "Epoch: 189 Loss: 0.3309587668070104\n",
            "Epoch: 190 Loss: 0.33095876680701053\n",
            "Epoch: 191 Loss: 0.3309587668070104\n",
            "Epoch: 192 Loss: 0.3309587668070105\n",
            "Epoch: 193 Loss: 0.3309587668070105\n",
            "Epoch: 194 Loss: 0.3309587668070105\n",
            "Epoch: 195 Loss: 0.33095876680701036\n",
            "Epoch: 196 Loss: 0.3309587668070105\n",
            "Epoch: 197 Loss: 0.33095876680701036\n",
            "Epoch: 198 Loss: 0.33095876680701036\n",
            "Epoch: 199 Loss: 0.33095876680701053\n",
            "Epoch: 200 Loss: 0.3309587668070104\n",
            "Epoch: 201 Loss: 0.3309587668070103\n",
            "Epoch: 202 Loss: 0.3309587668070104\n",
            "Epoch: 203 Loss: 0.3309587668070105\n",
            "Epoch: 204 Loss: 0.3309587668070103\n",
            "Epoch: 205 Loss: 0.33095876680701053\n",
            "Epoch: 206 Loss: 0.3309587668070105\n",
            "Epoch: 207 Loss: 0.33095876680701036\n",
            "Epoch: 208 Loss: 0.3309587668070104\n",
            "Epoch: 209 Loss: 0.33095876680701036\n",
            "Epoch: 210 Loss: 0.3309587668070103\n",
            "Epoch: 211 Loss: 0.3309587668070103\n",
            "Epoch: 212 Loss: 0.33095876680701036\n",
            "Epoch: 213 Loss: 0.33095876680701053\n",
            "Epoch: 214 Loss: 0.3309587668070103\n",
            "Epoch: 215 Loss: 0.3309587668070104\n",
            "Epoch: 216 Loss: 0.33095876680701036\n",
            "Epoch: 217 Loss: 0.3309587668070105\n",
            "Epoch: 218 Loss: 0.3309587668070105\n",
            "Epoch: 219 Loss: 0.3309587668070105\n",
            "Epoch: 220 Loss: 0.3309587668070105\n",
            "Epoch: 221 Loss: 0.33095876680701036\n",
            "Epoch: 222 Loss: 0.3309587668070105\n",
            "Epoch: 223 Loss: 0.3309587668070105\n",
            "Epoch: 224 Loss: 0.3309587668070105\n",
            "Epoch: 225 Loss: 0.33095876680701036\n",
            "Epoch: 226 Loss: 0.3309587668070104\n",
            "Epoch: 227 Loss: 0.3309587668070105\n",
            "Epoch: 228 Loss: 0.3309587668070104\n",
            "Epoch: 229 Loss: 0.3309587668070105\n",
            "Epoch: 230 Loss: 0.3309587668070105\n",
            "Epoch: 231 Loss: 0.3309587668070105\n",
            "Epoch: 232 Loss: 0.33095876680701036\n",
            "Epoch: 233 Loss: 0.33095876680701036\n",
            "Epoch: 234 Loss: 0.3309587668070104\n",
            "Epoch: 235 Loss: 0.3309587668070105\n",
            "Epoch: 236 Loss: 0.3309587668070105\n",
            "Epoch: 237 Loss: 0.33095876680701036\n",
            "Epoch: 238 Loss: 0.3309587668070104\n",
            "Epoch: 239 Loss: 0.3309587668070103\n",
            "Epoch: 240 Loss: 0.3309587668070105\n",
            "Epoch: 241 Loss: 0.3309587668070105\n",
            "Epoch: 242 Loss: 0.3309587668070105\n",
            "Epoch: 243 Loss: 0.33095876680701053\n",
            "Epoch: 244 Loss: 0.3309587668070104\n",
            "Epoch: 245 Loss: 0.3309587668070105\n",
            "Epoch: 246 Loss: 0.33095876680701053\n",
            "Epoch: 247 Loss: 0.33095876680701036\n",
            "Epoch: 248 Loss: 0.33095876680701036\n",
            "Epoch: 249 Loss: 0.3309587668070105\n",
            "Epoch: 250 Loss: 0.33095876680701036\n",
            "Epoch: 251 Loss: 0.3309587668070105\n",
            "Epoch: 252 Loss: 0.33095876680701036\n",
            "Epoch: 253 Loss: 0.33095876680701036\n",
            "Epoch: 254 Loss: 0.3309587668070104\n",
            "Epoch: 255 Loss: 0.33095876680701053\n",
            "Epoch: 256 Loss: 0.33095876680701036\n",
            "Epoch: 257 Loss: 0.33095876680701036\n",
            "Epoch: 258 Loss: 0.3309587668070104\n",
            "Epoch: 259 Loss: 0.3309587668070105\n",
            "Epoch: 260 Loss: 0.3309587668070105\n",
            "Epoch: 261 Loss: 0.33095876680701036\n",
            "Epoch: 262 Loss: 0.3309587668070105\n",
            "Epoch: 263 Loss: 0.33095876680701053\n",
            "Epoch: 264 Loss: 0.3309587668070105\n",
            "Epoch: 265 Loss: 0.3309587668070103\n",
            "Epoch: 266 Loss: 0.33095876680701053\n",
            "Epoch: 267 Loss: 0.3309587668070104\n",
            "Epoch: 268 Loss: 0.3309587668070105\n",
            "Epoch: 269 Loss: 0.3309587668070105\n",
            "Epoch: 270 Loss: 0.3309587668070104\n",
            "Epoch: 271 Loss: 0.3309587668070105\n",
            "Epoch: 272 Loss: 0.3309587668070105\n",
            "Epoch: 273 Loss: 0.3309587668070105\n",
            "Epoch: 274 Loss: 0.33095876680701036\n",
            "Epoch: 275 Loss: 0.3309587668070104\n",
            "Epoch: 276 Loss: 0.3309587668070103\n",
            "Epoch: 277 Loss: 0.33095876680701036\n",
            "Epoch: 278 Loss: 0.33095876680701053\n",
            "Epoch: 279 Loss: 0.3309587668070105\n",
            "Epoch: 280 Loss: 0.33095876680701053\n",
            "Epoch: 281 Loss: 0.3309587668070105\n",
            "Epoch: 282 Loss: 0.3309587668070103\n",
            "Epoch: 283 Loss: 0.33095876680701036\n",
            "Epoch: 284 Loss: 0.33095876680701036\n",
            "Epoch: 285 Loss: 0.33095876680701036\n",
            "Epoch: 286 Loss: 0.33095876680701036\n",
            "Epoch: 287 Loss: 0.3309587668070105\n",
            "Epoch: 288 Loss: 0.3309587668070105\n",
            "Epoch: 289 Loss: 0.3309587668070105\n",
            "Epoch: 290 Loss: 0.3309587668070105\n",
            "Epoch: 291 Loss: 0.3309587668070105\n",
            "Epoch: 292 Loss: 0.3309587668070105\n",
            "Epoch: 293 Loss: 0.3309587668070103\n",
            "Epoch: 294 Loss: 0.3309587668070103\n",
            "Epoch: 295 Loss: 0.33095876680701036\n",
            "Epoch: 296 Loss: 0.33095876680701036\n",
            "Epoch: 297 Loss: 0.33095876680701036\n",
            "Epoch: 298 Loss: 0.33095876680701036\n",
            "Epoch: 299 Loss: 0.33095876680701036\n",
            "Epoch: 300 Loss: 0.33095876680701036\n",
            "Epoch: 301 Loss: 0.33095876680701036\n",
            "Epoch: 302 Loss: 0.33095876680701036\n",
            "Epoch: 303 Loss: 0.3309587668070103\n",
            "Epoch: 304 Loss: 0.3309587668070103\n",
            "Epoch: 305 Loss: 0.3309587668070103\n",
            "Epoch: 306 Loss: 0.3309587668070103\n",
            "Epoch: 307 Loss: 0.3309587668070103\n",
            "Epoch: 308 Loss: 0.3309587668070103\n",
            "Epoch: 309 Loss: 0.3309587668070103\n",
            "Epoch: 310 Loss: 0.3309587668070103\n",
            "Epoch: 311 Loss: 0.3309587668070103\n",
            "Epoch: 312 Loss: 0.3309587668070103\n",
            "Epoch: 313 Loss: 0.3309587668070103\n",
            "Epoch: 314 Loss: 0.3309587668070103\n",
            "Epoch: 315 Loss: 0.3309587668070103\n",
            "Epoch: 316 Loss: 0.3309587668070103\n",
            "Epoch: 317 Loss: 0.3309587668070103\n",
            "Epoch: 318 Loss: 0.3309587668070103\n",
            "Epoch: 319 Loss: 0.3309587668070103\n",
            "Epoch: 320 Loss: 0.3309587668070103\n",
            "Epoch: 321 Loss: 0.3309587668070103\n",
            "Epoch: 322 Loss: 0.33095876680701036\n",
            "Epoch: 323 Loss: 0.33095876680701036\n",
            "Epoch: 324 Loss: 0.33095876680701036\n",
            "Epoch: 325 Loss: 0.33095876680701036\n",
            "Epoch: 326 Loss: 0.33095876680701036\n",
            "Epoch: 327 Loss: 0.33095876680701036\n",
            "Epoch: 328 Loss: 0.33095876680701036\n",
            "Epoch: 329 Loss: 0.33095876680701036\n",
            "Epoch: 330 Loss: 0.33095876680701036\n",
            "Epoch: 331 Loss: 0.33095876680701036\n",
            "Epoch: 332 Loss: 0.33095876680701036\n",
            "Epoch: 333 Loss: 0.33095876680701036\n",
            "Epoch: 334 Loss: 0.33095876680701036\n",
            "Epoch: 335 Loss: 0.33095876680701036\n",
            "Epoch: 336 Loss: 0.33095876680701036\n",
            "Epoch: 337 Loss: 0.33095876680701036\n",
            "Epoch: 338 Loss: 0.33095876680701036\n",
            "Epoch: 339 Loss: 0.33095876680701036\n",
            "Epoch: 340 Loss: 0.33095876680701036\n",
            "Epoch: 341 Loss: 0.33095876680701036\n",
            "Epoch: 342 Loss: 0.33095876680701036\n",
            "Epoch: 343 Loss: 0.3309587668070103\n",
            "Epoch: 344 Loss: 0.3309587668070103\n",
            "Epoch: 345 Loss: 0.3309587668070103\n",
            "Epoch: 346 Loss: 0.3309587668070103\n",
            "Epoch: 347 Loss: 0.3309587668070103\n",
            "Epoch: 348 Loss: 0.3309587668070103\n",
            "Epoch: 349 Loss: 0.3309587668070103\n",
            "Epoch: 350 Loss: 0.3309587668070103\n",
            "Epoch: 351 Loss: 0.3309587668070103\n",
            "Epoch: 352 Loss: 0.3309587668070103\n",
            "Epoch: 353 Loss: 0.3309587668070103\n",
            "Epoch: 354 Loss: 0.3309587668070103\n",
            "Epoch: 355 Loss: 0.3309587668070103\n",
            "Epoch: 356 Loss: 0.3309587668070103\n",
            "Epoch: 357 Loss: 0.3309587668070103\n",
            "Epoch: 358 Loss: 0.3309587668070103\n",
            "Epoch: 359 Loss: 0.3309587668070103\n",
            "Epoch: 360 Loss: 0.3309587668070103\n",
            "Epoch: 361 Loss: 0.3309587668070105\n",
            "Epoch: 362 Loss: 0.3309587668070105\n",
            "Epoch: 363 Loss: 0.3309587668070105\n",
            "Epoch: 364 Loss: 0.3309587668070105\n",
            "Epoch: 365 Loss: 0.3309587668070105\n",
            "Epoch: 366 Loss: 0.3309587668070105\n",
            "Epoch: 367 Loss: 0.3309587668070105\n",
            "Epoch: 368 Loss: 0.3309587668070105\n",
            "Epoch: 369 Loss: 0.3309587668070105\n",
            "Epoch: 370 Loss: 0.3309587668070105\n",
            "Epoch: 371 Loss: 0.3309587668070105\n",
            "Epoch: 372 Loss: 0.3309587668070105\n",
            "Epoch: 373 Loss: 0.3309587668070105\n",
            "Epoch: 374 Loss: 0.3309587668070105\n",
            "Epoch: 375 Loss: 0.3309587668070105\n",
            "Epoch: 376 Loss: 0.3309587668070105\n",
            "Epoch: 377 Loss: 0.3309587668070105\n",
            "Epoch: 378 Loss: 0.3309587668070105\n",
            "Epoch: 379 Loss: 0.3309587668070105\n",
            "Epoch: 380 Loss: 0.3309587668070105\n",
            "Epoch: 381 Loss: 0.3309587668070105\n",
            "Epoch: 382 Loss: 0.3309587668070105\n",
            "Epoch: 383 Loss: 0.3309587668070105\n",
            "Epoch: 384 Loss: 0.3309587668070105\n",
            "Epoch: 385 Loss: 0.3309587668070105\n",
            "Epoch: 386 Loss: 0.3309587668070105\n",
            "Epoch: 387 Loss: 0.3309587668070105\n",
            "Epoch: 388 Loss: 0.3309587668070105\n",
            "Epoch: 389 Loss: 0.3309587668070105\n",
            "Epoch: 390 Loss: 0.3309587668070105\n",
            "Epoch: 391 Loss: 0.3309587668070105\n",
            "Epoch: 392 Loss: 0.3309587668070105\n",
            "Epoch: 393 Loss: 0.3309587668070105\n",
            "Epoch: 394 Loss: 0.3309587668070105\n",
            "Epoch: 395 Loss: 0.3309587668070105\n",
            "Epoch: 396 Loss: 0.3309587668070105\n",
            "Epoch: 397 Loss: 0.3309587668070105\n",
            "Epoch: 398 Loss: 0.3309587668070105\n",
            "Epoch: 399 Loss: 0.3309587668070105\n",
            "Epoch: 400 Loss: 0.3309587668070105\n",
            "Epoch: 401 Loss: 0.3309587668070105\n",
            "Epoch: 402 Loss: 0.3309587668070105\n",
            "Epoch: 403 Loss: 0.3309587668070105\n",
            "Epoch: 404 Loss: 0.3309587668070105\n",
            "Epoch: 405 Loss: 0.3309587668070105\n",
            "Epoch: 406 Loss: 0.3309587668070105\n",
            "Epoch: 407 Loss: 0.3309587668070105\n",
            "Epoch: 408 Loss: 0.3309587668070105\n",
            "Epoch: 409 Loss: 0.3309587668070105\n",
            "Epoch: 410 Loss: 0.3309587668070105\n",
            "Epoch: 411 Loss: 0.3309587668070105\n",
            "Epoch: 412 Loss: 0.3309587668070105\n",
            "Epoch: 413 Loss: 0.3309587668070105\n",
            "Epoch: 414 Loss: 0.3309587668070105\n",
            "Epoch: 415 Loss: 0.3309587668070105\n",
            "Epoch: 416 Loss: 0.3309587668070105\n",
            "Epoch: 417 Loss: 0.3309587668070105\n",
            "Epoch: 418 Loss: 0.3309587668070105\n",
            "Epoch: 419 Loss: 0.3309587668070105\n",
            "Epoch: 420 Loss: 0.3309587668070105\n",
            "Epoch: 421 Loss: 0.3309587668070105\n",
            "Epoch: 422 Loss: 0.3309587668070105\n",
            "Epoch: 423 Loss: 0.3309587668070105\n",
            "Epoch: 424 Loss: 0.3309587668070105\n",
            "Epoch: 425 Loss: 0.3309587668070105\n",
            "Epoch: 426 Loss: 0.3309587668070105\n",
            "Epoch: 427 Loss: 0.3309587668070105\n",
            "Epoch: 428 Loss: 0.3309587668070105\n",
            "Epoch: 429 Loss: 0.3309587668070105\n",
            "Epoch: 430 Loss: 0.3309587668070105\n",
            "Epoch: 431 Loss: 0.3309587668070105\n",
            "Epoch: 432 Loss: 0.3309587668070105\n",
            "Epoch: 433 Loss: 0.3309587668070105\n",
            "Epoch: 434 Loss: 0.3309587668070105\n",
            "Epoch: 435 Loss: 0.3309587668070105\n",
            "Epoch: 436 Loss: 0.3309587668070105\n",
            "Epoch: 437 Loss: 0.3309587668070105\n",
            "Epoch: 438 Loss: 0.3309587668070105\n",
            "Epoch: 439 Loss: 0.3309587668070105\n",
            "Epoch: 440 Loss: 0.3309587668070105\n",
            "Epoch: 441 Loss: 0.3309587668070105\n",
            "Epoch: 442 Loss: 0.3309587668070105\n",
            "Epoch: 443 Loss: 0.3309587668070105\n",
            "Epoch: 444 Loss: 0.3309587668070105\n",
            "Epoch: 445 Loss: 0.3309587668070105\n",
            "Epoch: 446 Loss: 0.3309587668070105\n",
            "Epoch: 447 Loss: 0.3309587668070105\n",
            "Epoch: 448 Loss: 0.3309587668070105\n",
            "Epoch: 449 Loss: 0.3309587668070105\n",
            "Epoch: 450 Loss: 0.3309587668070105\n",
            "Epoch: 451 Loss: 0.3309587668070105\n",
            "Epoch: 452 Loss: 0.3309587668070105\n",
            "Epoch: 453 Loss: 0.3309587668070105\n",
            "Epoch: 454 Loss: 0.3309587668070105\n",
            "Epoch: 455 Loss: 0.3309587668070105\n",
            "Epoch: 456 Loss: 0.3309587668070105\n",
            "Epoch: 457 Loss: 0.3309587668070105\n",
            "Epoch: 458 Loss: 0.3309587668070105\n",
            "Epoch: 459 Loss: 0.3309587668070105\n",
            "Epoch: 460 Loss: 0.3309587668070105\n",
            "Epoch: 461 Loss: 0.3309587668070105\n",
            "Epoch: 462 Loss: 0.3309587668070105\n",
            "Epoch: 463 Loss: 0.3309587668070105\n",
            "Epoch: 464 Loss: 0.3309587668070105\n",
            "Epoch: 465 Loss: 0.3309587668070105\n",
            "Epoch: 466 Loss: 0.3309587668070105\n",
            "Epoch: 467 Loss: 0.3309587668070105\n",
            "Epoch: 468 Loss: 0.3309587668070105\n",
            "Epoch: 469 Loss: 0.3309587668070105\n",
            "Epoch: 470 Loss: 0.3309587668070105\n",
            "Epoch: 471 Loss: 0.3309587668070105\n",
            "Epoch: 472 Loss: 0.3309587668070105\n",
            "Epoch: 473 Loss: 0.3309587668070105\n",
            "Epoch: 474 Loss: 0.3309587668070105\n",
            "Epoch: 475 Loss: 0.3309587668070105\n",
            "Epoch: 476 Loss: 0.3309587668070105\n",
            "Epoch: 477 Loss: 0.3309587668070105\n",
            "Epoch: 478 Loss: 0.3309587668070105\n",
            "Epoch: 479 Loss: 0.3309587668070105\n",
            "Epoch: 480 Loss: 0.3309587668070105\n",
            "Epoch: 481 Loss: 0.3309587668070105\n",
            "Epoch: 482 Loss: 0.3309587668070105\n",
            "Epoch: 483 Loss: 0.3309587668070105\n",
            "Epoch: 484 Loss: 0.3309587668070105\n",
            "Epoch: 485 Loss: 0.3309587668070105\n",
            "Epoch: 486 Loss: 0.3309587668070105\n",
            "Epoch: 487 Loss: 0.3309587668070105\n",
            "Epoch: 488 Loss: 0.3309587668070105\n",
            "Epoch: 489 Loss: 0.3309587668070105\n",
            "Epoch: 490 Loss: 0.3309587668070105\n",
            "Epoch: 491 Loss: 0.3309587668070105\n",
            "Epoch: 492 Loss: 0.3309587668070105\n",
            "Epoch: 493 Loss: 0.3309587668070105\n",
            "Epoch: 494 Loss: 0.3309587668070105\n",
            "Epoch: 495 Loss: 0.3309587668070105\n",
            "Epoch: 496 Loss: 0.3309587668070105\n",
            "Epoch: 497 Loss: 0.3309587668070105\n",
            "Epoch: 498 Loss: 0.3309587668070105\n",
            "Epoch: 499 Loss: 0.3309587668070105\n",
            "Epoch: 500 Loss: 0.3309587668070105\n",
            "Epoch: 501 Loss: 0.3309587668070105\n",
            "Epoch: 502 Loss: 0.3309587668070105\n",
            "Epoch: 503 Loss: 0.3309587668070105\n",
            "Epoch: 504 Loss: 0.3309587668070105\n",
            "Epoch: 505 Loss: 0.3309587668070105\n",
            "Epoch: 506 Loss: 0.3309587668070105\n",
            "Epoch: 507 Loss: 0.3309587668070105\n",
            "Epoch: 508 Loss: 0.3309587668070105\n",
            "Epoch: 509 Loss: 0.3309587668070105\n",
            "Epoch: 510 Loss: 0.3309587668070105\n",
            "Epoch: 511 Loss: 0.3309587668070105\n",
            "Epoch: 512 Loss: 0.3309587668070105\n",
            "Epoch: 513 Loss: 0.3309587668070105\n",
            "Epoch: 514 Loss: 0.3309587668070105\n",
            "Epoch: 515 Loss: 0.3309587668070105\n",
            "Epoch: 516 Loss: 0.3309587668070105\n",
            "Epoch: 517 Loss: 0.3309587668070105\n",
            "Epoch: 518 Loss: 0.3309587668070105\n",
            "Epoch: 519 Loss: 0.3309587668070105\n",
            "Epoch: 520 Loss: 0.3309587668070105\n",
            "Epoch: 521 Loss: 0.3309587668070105\n",
            "Epoch: 522 Loss: 0.3309587668070105\n",
            "Epoch: 523 Loss: 0.3309587668070105\n",
            "Epoch: 524 Loss: 0.3309587668070105\n",
            "Epoch: 525 Loss: 0.3309587668070105\n",
            "Epoch: 526 Loss: 0.3309587668070105\n",
            "Epoch: 527 Loss: 0.3309587668070105\n",
            "Epoch: 528 Loss: 0.3309587668070105\n",
            "Epoch: 529 Loss: 0.3309587668070105\n",
            "Epoch: 530 Loss: 0.3309587668070105\n",
            "Epoch: 531 Loss: 0.3309587668070105\n",
            "Epoch: 532 Loss: 0.3309587668070105\n",
            "Epoch: 533 Loss: 0.3309587668070105\n",
            "Epoch: 534 Loss: 0.3309587668070105\n",
            "Epoch: 535 Loss: 0.3309587668070105\n",
            "Epoch: 536 Loss: 0.3309587668070105\n",
            "Epoch: 537 Loss: 0.3309587668070105\n",
            "Epoch: 538 Loss: 0.3309587668070105\n",
            "Epoch: 539 Loss: 0.3309587668070105\n",
            "Epoch: 540 Loss: 0.3309587668070105\n",
            "Epoch: 541 Loss: 0.3309587668070105\n",
            "Epoch: 542 Loss: 0.3309587668070105\n",
            "Epoch: 543 Loss: 0.3309587668070105\n",
            "Epoch: 544 Loss: 0.3309587668070105\n",
            "Epoch: 545 Loss: 0.3309587668070105\n",
            "Epoch: 546 Loss: 0.3309587668070105\n",
            "Epoch: 547 Loss: 0.3309587668070105\n",
            "Epoch: 548 Loss: 0.3309587668070105\n",
            "Epoch: 549 Loss: 0.3309587668070105\n",
            "Epoch: 550 Loss: 0.3309587668070105\n",
            "Epoch: 551 Loss: 0.3309587668070105\n",
            "Epoch: 552 Loss: 0.3309587668070105\n",
            "Epoch: 553 Loss: 0.3309587668070105\n",
            "Epoch: 554 Loss: 0.3309587668070105\n",
            "Epoch: 555 Loss: 0.3309587668070105\n",
            "Epoch: 556 Loss: 0.3309587668070105\n",
            "Epoch: 557 Loss: 0.3309587668070105\n",
            "Epoch: 558 Loss: 0.3309587668070105\n",
            "Epoch: 559 Loss: 0.3309587668070105\n",
            "Epoch: 560 Loss: 0.3309587668070105\n",
            "Epoch: 561 Loss: 0.3309587668070105\n",
            "Epoch: 562 Loss: 0.3309587668070105\n",
            "Epoch: 563 Loss: 0.3309587668070105\n",
            "Epoch: 564 Loss: 0.3309587668070105\n",
            "Epoch: 565 Loss: 0.3309587668070105\n",
            "Epoch: 566 Loss: 0.3309587668070105\n",
            "Epoch: 567 Loss: 0.3309587668070105\n",
            "Epoch: 568 Loss: 0.3309587668070105\n",
            "Epoch: 569 Loss: 0.3309587668070105\n",
            "Epoch: 570 Loss: 0.3309587668070105\n",
            "Epoch: 571 Loss: 0.3309587668070105\n",
            "Epoch: 572 Loss: 0.3309587668070105\n",
            "Epoch: 573 Loss: 0.3309587668070105\n",
            "Epoch: 574 Loss: 0.3309587668070105\n",
            "Epoch: 575 Loss: 0.3309587668070105\n",
            "Epoch: 576 Loss: 0.3309587668070105\n",
            "Epoch: 577 Loss: 0.3309587668070105\n",
            "Epoch: 578 Loss: 0.3309587668070105\n",
            "Epoch: 579 Loss: 0.3309587668070105\n",
            "Epoch: 580 Loss: 0.3309587668070105\n",
            "Epoch: 581 Loss: 0.3309587668070105\n",
            "Epoch: 582 Loss: 0.3309587668070105\n",
            "Epoch: 583 Loss: 0.3309587668070105\n",
            "Epoch: 584 Loss: 0.3309587668070105\n",
            "Epoch: 585 Loss: 0.3309587668070105\n",
            "Epoch: 586 Loss: 0.3309587668070105\n",
            "Epoch: 587 Loss: 0.3309587668070105\n",
            "Epoch: 588 Loss: 0.3309587668070105\n",
            "Epoch: 589 Loss: 0.3309587668070105\n",
            "Epoch: 590 Loss: 0.3309587668070105\n",
            "Epoch: 591 Loss: 0.3309587668070105\n",
            "Epoch: 592 Loss: 0.3309587668070105\n",
            "Epoch: 593 Loss: 0.3309587668070105\n",
            "Epoch: 594 Loss: 0.3309587668070105\n",
            "Epoch: 595 Loss: 0.3309587668070105\n",
            "Epoch: 596 Loss: 0.3309587668070105\n",
            "Epoch: 597 Loss: 0.3309587668070105\n",
            "Epoch: 598 Loss: 0.3309587668070105\n",
            "Epoch: 599 Loss: 0.3309587668070105\n",
            "Epoch: 600 Loss: 0.3309587668070105\n",
            "Epoch: 601 Loss: 0.3309587668070105\n",
            "Epoch: 602 Loss: 0.3309587668070105\n",
            "Epoch: 603 Loss: 0.3309587668070105\n",
            "Epoch: 604 Loss: 0.3309587668070105\n",
            "Epoch: 605 Loss: 0.3309587668070105\n",
            "Epoch: 606 Loss: 0.3309587668070105\n",
            "Epoch: 607 Loss: 0.3309587668070105\n",
            "Epoch: 608 Loss: 0.3309587668070105\n",
            "Epoch: 609 Loss: 0.3309587668070105\n",
            "Epoch: 610 Loss: 0.3309587668070105\n",
            "Epoch: 611 Loss: 0.3309587668070105\n",
            "Epoch: 612 Loss: 0.3309587668070105\n",
            "Epoch: 613 Loss: 0.3309587668070105\n",
            "Epoch: 614 Loss: 0.3309587668070105\n",
            "Epoch: 615 Loss: 0.3309587668070105\n",
            "Epoch: 616 Loss: 0.3309587668070105\n",
            "Epoch: 617 Loss: 0.3309587668070105\n",
            "Epoch: 618 Loss: 0.3309587668070105\n",
            "Epoch: 619 Loss: 0.3309587668070105\n",
            "Epoch: 620 Loss: 0.3309587668070105\n",
            "Epoch: 621 Loss: 0.3309587668070105\n",
            "Epoch: 622 Loss: 0.3309587668070105\n",
            "Epoch: 623 Loss: 0.3309587668070105\n",
            "Epoch: 624 Loss: 0.3309587668070105\n",
            "Epoch: 625 Loss: 0.3309587668070105\n",
            "Epoch: 626 Loss: 0.3309587668070105\n",
            "Epoch: 627 Loss: 0.3309587668070105\n",
            "Epoch: 628 Loss: 0.3309587668070105\n",
            "Epoch: 629 Loss: 0.3309587668070105\n",
            "Epoch: 630 Loss: 0.3309587668070105\n",
            "Epoch: 631 Loss: 0.3309587668070105\n",
            "Epoch: 632 Loss: 0.3309587668070105\n",
            "Epoch: 633 Loss: 0.3309587668070105\n",
            "Epoch: 634 Loss: 0.3309587668070105\n",
            "Epoch: 635 Loss: 0.3309587668070105\n",
            "Epoch: 636 Loss: 0.3309587668070105\n",
            "Epoch: 637 Loss: 0.3309587668070105\n",
            "Epoch: 638 Loss: 0.3309587668070105\n",
            "Epoch: 639 Loss: 0.3309587668070105\n",
            "Epoch: 640 Loss: 0.3309587668070105\n",
            "Epoch: 641 Loss: 0.3309587668070105\n",
            "Epoch: 642 Loss: 0.3309587668070105\n",
            "Epoch: 643 Loss: 0.3309587668070105\n",
            "Epoch: 644 Loss: 0.3309587668070105\n",
            "Epoch: 645 Loss: 0.3309587668070105\n",
            "Epoch: 646 Loss: 0.3309587668070105\n",
            "Epoch: 647 Loss: 0.3309587668070105\n",
            "Epoch: 648 Loss: 0.3309587668070105\n",
            "Epoch: 649 Loss: 0.3309587668070105\n",
            "Epoch: 650 Loss: 0.3309587668070105\n",
            "Epoch: 651 Loss: 0.3309587668070105\n",
            "Epoch: 652 Loss: 0.3309587668070105\n",
            "Epoch: 653 Loss: 0.3309587668070105\n",
            "Epoch: 654 Loss: 0.3309587668070105\n",
            "Epoch: 655 Loss: 0.3309587668070105\n",
            "Epoch: 656 Loss: 0.3309587668070105\n",
            "Epoch: 657 Loss: 0.3309587668070105\n",
            "Epoch: 658 Loss: 0.3309587668070105\n",
            "Epoch: 659 Loss: 0.3309587668070105\n",
            "Epoch: 660 Loss: 0.3309587668070105\n",
            "Epoch: 661 Loss: 0.3309587668070105\n",
            "Epoch: 662 Loss: 0.3309587668070105\n",
            "Epoch: 663 Loss: 0.3309587668070105\n",
            "Epoch: 664 Loss: 0.3309587668070105\n",
            "Epoch: 665 Loss: 0.3309587668070105\n",
            "Epoch: 666 Loss: 0.3309587668070105\n",
            "Epoch: 667 Loss: 0.3309587668070105\n",
            "Epoch: 668 Loss: 0.3309587668070105\n",
            "Epoch: 669 Loss: 0.3309587668070105\n",
            "Epoch: 670 Loss: 0.3309587668070105\n",
            "Epoch: 671 Loss: 0.3309587668070105\n",
            "Epoch: 672 Loss: 0.3309587668070105\n",
            "Epoch: 673 Loss: 0.3309587668070105\n",
            "Epoch: 674 Loss: 0.3309587668070105\n",
            "Epoch: 675 Loss: 0.3309587668070105\n",
            "Epoch: 676 Loss: 0.3309587668070105\n",
            "Epoch: 677 Loss: 0.3309587668070105\n",
            "Epoch: 678 Loss: 0.3309587668070105\n",
            "Epoch: 679 Loss: 0.3309587668070105\n",
            "Epoch: 680 Loss: 0.3309587668070105\n",
            "Epoch: 681 Loss: 0.3309587668070105\n",
            "Epoch: 682 Loss: 0.3309587668070105\n",
            "Epoch: 683 Loss: 0.3309587668070105\n",
            "Epoch: 684 Loss: 0.3309587668070105\n",
            "Epoch: 685 Loss: 0.3309587668070105\n",
            "Epoch: 686 Loss: 0.3309587668070105\n",
            "Epoch: 687 Loss: 0.3309587668070105\n",
            "Epoch: 688 Loss: 0.3309587668070105\n",
            "Epoch: 689 Loss: 0.3309587668070105\n",
            "Epoch: 690 Loss: 0.3309587668070105\n",
            "Epoch: 691 Loss: 0.3309587668070105\n",
            "Epoch: 692 Loss: 0.3309587668070105\n",
            "Epoch: 693 Loss: 0.3309587668070105\n",
            "Epoch: 694 Loss: 0.3309587668070105\n",
            "Epoch: 695 Loss: 0.3309587668070105\n",
            "Epoch: 696 Loss: 0.3309587668070105\n",
            "Epoch: 697 Loss: 0.3309587668070105\n",
            "Epoch: 698 Loss: 0.3309587668070105\n",
            "Epoch: 699 Loss: 0.3309587668070105\n",
            "Epoch: 700 Loss: 0.3309587668070105\n",
            "Epoch: 701 Loss: 0.3309587668070105\n",
            "Epoch: 702 Loss: 0.3309587668070105\n",
            "Epoch: 703 Loss: 0.3309587668070105\n",
            "Epoch: 704 Loss: 0.3309587668070105\n",
            "Epoch: 705 Loss: 0.3309587668070105\n",
            "Epoch: 706 Loss: 0.3309587668070105\n",
            "Epoch: 707 Loss: 0.3309587668070105\n",
            "Epoch: 708 Loss: 0.3309587668070105\n",
            "Epoch: 709 Loss: 0.3309587668070105\n",
            "Epoch: 710 Loss: 0.3309587668070105\n",
            "Epoch: 711 Loss: 0.3309587668070105\n",
            "Epoch: 712 Loss: 0.3309587668070105\n",
            "Epoch: 713 Loss: 0.3309587668070105\n",
            "Epoch: 714 Loss: 0.3309587668070105\n",
            "Epoch: 715 Loss: 0.3309587668070105\n",
            "Epoch: 716 Loss: 0.3309587668070105\n",
            "Epoch: 717 Loss: 0.3309587668070105\n",
            "Epoch: 718 Loss: 0.3309587668070105\n",
            "Epoch: 719 Loss: 0.3309587668070105\n",
            "Epoch: 720 Loss: 0.3309587668070105\n",
            "Epoch: 721 Loss: 0.3309587668070105\n",
            "Epoch: 722 Loss: 0.3309587668070105\n",
            "Epoch: 723 Loss: 0.3309587668070105\n",
            "Epoch: 724 Loss: 0.3309587668070105\n",
            "Epoch: 725 Loss: 0.3309587668070105\n",
            "Epoch: 726 Loss: 0.3309587668070105\n",
            "Epoch: 727 Loss: 0.3309587668070105\n",
            "Epoch: 728 Loss: 0.3309587668070105\n",
            "Epoch: 729 Loss: 0.3309587668070105\n",
            "Epoch: 730 Loss: 0.3309587668070105\n",
            "Epoch: 731 Loss: 0.3309587668070105\n",
            "Epoch: 732 Loss: 0.3309587668070105\n",
            "Epoch: 733 Loss: 0.3309587668070105\n",
            "Epoch: 734 Loss: 0.3309587668070105\n",
            "Epoch: 735 Loss: 0.3309587668070105\n",
            "Epoch: 736 Loss: 0.3309587668070105\n",
            "Epoch: 737 Loss: 0.3309587668070105\n",
            "Epoch: 738 Loss: 0.3309587668070105\n",
            "Epoch: 739 Loss: 0.3309587668070105\n",
            "Epoch: 740 Loss: 0.3309587668070105\n",
            "Epoch: 741 Loss: 0.3309587668070105\n",
            "Epoch: 742 Loss: 0.3309587668070105\n",
            "Epoch: 743 Loss: 0.3309587668070105\n",
            "Epoch: 744 Loss: 0.3309587668070105\n",
            "Epoch: 745 Loss: 0.3309587668070105\n",
            "Epoch: 746 Loss: 0.3309587668070105\n",
            "Epoch: 747 Loss: 0.3309587668070105\n",
            "Epoch: 748 Loss: 0.3309587668070105\n",
            "Epoch: 749 Loss: 0.3309587668070105\n",
            "Epoch: 750 Loss: 0.3309587668070105\n",
            "Epoch: 751 Loss: 0.3309587668070105\n",
            "Epoch: 752 Loss: 0.3309587668070105\n",
            "Epoch: 753 Loss: 0.3309587668070105\n",
            "Epoch: 754 Loss: 0.3309587668070105\n",
            "Epoch: 755 Loss: 0.3309587668070105\n",
            "Epoch: 756 Loss: 0.3309587668070105\n",
            "Epoch: 757 Loss: 0.3309587668070105\n",
            "Epoch: 758 Loss: 0.3309587668070105\n",
            "Epoch: 759 Loss: 0.3309587668070105\n",
            "Epoch: 760 Loss: 0.3309587668070105\n",
            "Epoch: 761 Loss: 0.3309587668070105\n",
            "Epoch: 762 Loss: 0.3309587668070105\n",
            "Epoch: 763 Loss: 0.3309587668070105\n",
            "Epoch: 764 Loss: 0.3309587668070105\n",
            "Epoch: 765 Loss: 0.3309587668070105\n",
            "Epoch: 766 Loss: 0.3309587668070105\n",
            "Epoch: 767 Loss: 0.3309587668070105\n",
            "Epoch: 768 Loss: 0.3309587668070105\n",
            "Epoch: 769 Loss: 0.3309587668070105\n",
            "Epoch: 770 Loss: 0.3309587668070105\n",
            "Epoch: 771 Loss: 0.3309587668070105\n",
            "Epoch: 772 Loss: 0.3309587668070105\n",
            "Epoch: 773 Loss: 0.3309587668070105\n",
            "Epoch: 774 Loss: 0.3309587668070105\n",
            "Epoch: 775 Loss: 0.3309587668070105\n",
            "Epoch: 776 Loss: 0.3309587668070105\n",
            "Epoch: 777 Loss: 0.3309587668070105\n",
            "Epoch: 778 Loss: 0.3309587668070105\n",
            "Epoch: 779 Loss: 0.3309587668070105\n",
            "Epoch: 780 Loss: 0.3309587668070105\n",
            "Epoch: 781 Loss: 0.3309587668070105\n",
            "Epoch: 782 Loss: 0.3309587668070105\n",
            "Epoch: 783 Loss: 0.3309587668070105\n",
            "Epoch: 784 Loss: 0.3309587668070105\n",
            "Epoch: 785 Loss: 0.3309587668070105\n",
            "Epoch: 786 Loss: 0.3309587668070105\n",
            "Epoch: 787 Loss: 0.3309587668070105\n",
            "Epoch: 788 Loss: 0.3309587668070105\n",
            "Epoch: 789 Loss: 0.3309587668070105\n",
            "Epoch: 790 Loss: 0.3309587668070105\n",
            "Epoch: 791 Loss: 0.3309587668070105\n",
            "Epoch: 792 Loss: 0.3309587668070105\n",
            "Epoch: 793 Loss: 0.3309587668070105\n",
            "Epoch: 794 Loss: 0.3309587668070105\n",
            "Epoch: 795 Loss: 0.3309587668070105\n",
            "Epoch: 796 Loss: 0.3309587668070105\n",
            "Epoch: 797 Loss: 0.3309587668070105\n",
            "Epoch: 798 Loss: 0.3309587668070105\n",
            "Epoch: 799 Loss: 0.3309587668070105\n",
            "Epoch: 800 Loss: 0.3309587668070105\n",
            "Epoch: 801 Loss: 0.3309587668070105\n",
            "Epoch: 802 Loss: 0.3309587668070105\n",
            "Epoch: 803 Loss: 0.3309587668070105\n",
            "Epoch: 804 Loss: 0.3309587668070105\n",
            "Epoch: 805 Loss: 0.3309587668070105\n",
            "Epoch: 806 Loss: 0.3309587668070105\n",
            "Epoch: 807 Loss: 0.3309587668070105\n",
            "Epoch: 808 Loss: 0.3309587668070105\n",
            "Epoch: 809 Loss: 0.3309587668070105\n",
            "Epoch: 810 Loss: 0.3309587668070105\n",
            "Epoch: 811 Loss: 0.3309587668070105\n",
            "Epoch: 812 Loss: 0.3309587668070105\n",
            "Epoch: 813 Loss: 0.3309587668070105\n",
            "Epoch: 814 Loss: 0.3309587668070105\n",
            "Epoch: 815 Loss: 0.3309587668070105\n",
            "Epoch: 816 Loss: 0.3309587668070105\n",
            "Epoch: 817 Loss: 0.3309587668070105\n",
            "Epoch: 818 Loss: 0.3309587668070105\n",
            "Epoch: 819 Loss: 0.3309587668070105\n",
            "Epoch: 820 Loss: 0.3309587668070105\n",
            "Epoch: 821 Loss: 0.3309587668070105\n",
            "Epoch: 822 Loss: 0.3309587668070105\n",
            "Epoch: 823 Loss: 0.3309587668070105\n",
            "Epoch: 824 Loss: 0.3309587668070105\n",
            "Epoch: 825 Loss: 0.3309587668070105\n",
            "Epoch: 826 Loss: 0.3309587668070105\n",
            "Epoch: 827 Loss: 0.3309587668070105\n",
            "Epoch: 828 Loss: 0.3309587668070105\n",
            "Epoch: 829 Loss: 0.3309587668070105\n",
            "Epoch: 830 Loss: 0.3309587668070105\n",
            "Epoch: 831 Loss: 0.3309587668070105\n",
            "Epoch: 832 Loss: 0.3309587668070105\n",
            "Epoch: 833 Loss: 0.3309587668070105\n",
            "Epoch: 834 Loss: 0.3309587668070105\n",
            "Epoch: 835 Loss: 0.3309587668070105\n",
            "Epoch: 836 Loss: 0.3309587668070105\n",
            "Epoch: 837 Loss: 0.3309587668070105\n",
            "Epoch: 838 Loss: 0.3309587668070105\n",
            "Epoch: 839 Loss: 0.3309587668070105\n",
            "Epoch: 840 Loss: 0.3309587668070105\n",
            "Epoch: 841 Loss: 0.3309587668070105\n",
            "Epoch: 842 Loss: 0.3309587668070105\n",
            "Epoch: 843 Loss: 0.3309587668070105\n",
            "Epoch: 844 Loss: 0.3309587668070105\n",
            "Epoch: 845 Loss: 0.3309587668070105\n",
            "Epoch: 846 Loss: 0.3309587668070105\n",
            "Epoch: 847 Loss: 0.3309587668070105\n",
            "Epoch: 848 Loss: 0.3309587668070105\n",
            "Epoch: 849 Loss: 0.3309587668070105\n",
            "Epoch: 850 Loss: 0.3309587668070105\n",
            "Epoch: 851 Loss: 0.3309587668070105\n",
            "Epoch: 852 Loss: 0.3309587668070105\n",
            "Epoch: 853 Loss: 0.3309587668070105\n",
            "Epoch: 854 Loss: 0.3309587668070105\n",
            "Epoch: 855 Loss: 0.3309587668070105\n",
            "Epoch: 856 Loss: 0.3309587668070105\n",
            "Epoch: 857 Loss: 0.3309587668070105\n",
            "Epoch: 858 Loss: 0.3309587668070105\n",
            "Epoch: 859 Loss: 0.3309587668070105\n",
            "Epoch: 860 Loss: 0.3309587668070105\n",
            "Epoch: 861 Loss: 0.3309587668070105\n",
            "Epoch: 862 Loss: 0.3309587668070105\n",
            "Epoch: 863 Loss: 0.3309587668070105\n",
            "Epoch: 864 Loss: 0.3309587668070105\n",
            "Epoch: 865 Loss: 0.3309587668070105\n",
            "Epoch: 866 Loss: 0.3309587668070105\n",
            "Epoch: 867 Loss: 0.3309587668070105\n",
            "Epoch: 868 Loss: 0.3309587668070105\n",
            "Epoch: 869 Loss: 0.3309587668070105\n",
            "Epoch: 870 Loss: 0.3309587668070105\n",
            "Epoch: 871 Loss: 0.3309587668070105\n",
            "Epoch: 872 Loss: 0.3309587668070105\n",
            "Epoch: 873 Loss: 0.3309587668070105\n",
            "Epoch: 874 Loss: 0.3309587668070105\n",
            "Epoch: 875 Loss: 0.3309587668070105\n",
            "Epoch: 876 Loss: 0.3309587668070105\n",
            "Epoch: 877 Loss: 0.3309587668070105\n",
            "Epoch: 878 Loss: 0.3309587668070105\n",
            "Epoch: 879 Loss: 0.3309587668070105\n",
            "Epoch: 880 Loss: 0.3309587668070105\n",
            "Epoch: 881 Loss: 0.3309587668070105\n",
            "Epoch: 882 Loss: 0.3309587668070105\n",
            "Epoch: 883 Loss: 0.3309587668070105\n",
            "Epoch: 884 Loss: 0.3309587668070105\n",
            "Epoch: 885 Loss: 0.3309587668070105\n",
            "Epoch: 886 Loss: 0.3309587668070105\n",
            "Epoch: 887 Loss: 0.3309587668070105\n",
            "Epoch: 888 Loss: 0.3309587668070105\n",
            "Epoch: 889 Loss: 0.3309587668070105\n",
            "Epoch: 890 Loss: 0.3309587668070105\n",
            "Epoch: 891 Loss: 0.3309587668070105\n",
            "Epoch: 892 Loss: 0.3309587668070105\n",
            "Epoch: 893 Loss: 0.3309587668070105\n",
            "Epoch: 894 Loss: 0.3309587668070105\n",
            "Epoch: 895 Loss: 0.3309587668070105\n",
            "Epoch: 896 Loss: 0.3309587668070105\n",
            "Epoch: 897 Loss: 0.3309587668070105\n",
            "Epoch: 898 Loss: 0.3309587668070105\n",
            "Epoch: 899 Loss: 0.3309587668070105\n",
            "Epoch: 900 Loss: 0.3309587668070105\n",
            "Epoch: 901 Loss: 0.3309587668070105\n",
            "Epoch: 902 Loss: 0.3309587668070105\n",
            "Epoch: 903 Loss: 0.3309587668070105\n",
            "Epoch: 904 Loss: 0.3309587668070105\n",
            "Epoch: 905 Loss: 0.3309587668070105\n",
            "Epoch: 906 Loss: 0.3309587668070105\n",
            "Epoch: 907 Loss: 0.3309587668070105\n",
            "Epoch: 908 Loss: 0.3309587668070105\n",
            "Epoch: 909 Loss: 0.3309587668070105\n",
            "Epoch: 910 Loss: 0.3309587668070105\n",
            "Epoch: 911 Loss: 0.3309587668070105\n",
            "Epoch: 912 Loss: 0.3309587668070105\n",
            "Epoch: 913 Loss: 0.3309587668070105\n",
            "Epoch: 914 Loss: 0.3309587668070105\n",
            "Epoch: 915 Loss: 0.3309587668070105\n",
            "Epoch: 916 Loss: 0.3309587668070105\n",
            "Epoch: 917 Loss: 0.3309587668070105\n",
            "Epoch: 918 Loss: 0.3309587668070105\n",
            "Epoch: 919 Loss: 0.3309587668070105\n",
            "Epoch: 920 Loss: 0.3309587668070105\n",
            "Epoch: 921 Loss: 0.3309587668070105\n",
            "Epoch: 922 Loss: 0.3309587668070105\n",
            "Epoch: 923 Loss: 0.3309587668070105\n",
            "Epoch: 924 Loss: 0.3309587668070105\n",
            "Epoch: 925 Loss: 0.3309587668070105\n",
            "Epoch: 926 Loss: 0.3309587668070105\n",
            "Epoch: 927 Loss: 0.3309587668070105\n",
            "Epoch: 928 Loss: 0.3309587668070105\n",
            "Epoch: 929 Loss: 0.3309587668070105\n",
            "Epoch: 930 Loss: 0.3309587668070105\n",
            "Epoch: 931 Loss: 0.3309587668070105\n",
            "Epoch: 932 Loss: 0.3309587668070105\n",
            "Epoch: 933 Loss: 0.3309587668070105\n",
            "Epoch: 934 Loss: 0.3309587668070105\n",
            "Epoch: 935 Loss: 0.3309587668070105\n",
            "Epoch: 936 Loss: 0.3309587668070105\n",
            "Epoch: 937 Loss: 0.3309587668070105\n",
            "Epoch: 938 Loss: 0.3309587668070105\n",
            "Epoch: 939 Loss: 0.3309587668070105\n",
            "Epoch: 940 Loss: 0.3309587668070105\n",
            "Epoch: 941 Loss: 0.3309587668070105\n",
            "Epoch: 942 Loss: 0.3309587668070105\n",
            "Epoch: 943 Loss: 0.3309587668070105\n",
            "Epoch: 944 Loss: 0.3309587668070105\n",
            "Epoch: 945 Loss: 0.3309587668070105\n",
            "Epoch: 946 Loss: 0.3309587668070105\n",
            "Epoch: 947 Loss: 0.3309587668070105\n",
            "Epoch: 948 Loss: 0.3309587668070105\n",
            "Epoch: 949 Loss: 0.3309587668070105\n",
            "Epoch: 950 Loss: 0.3309587668070105\n",
            "Epoch: 951 Loss: 0.3309587668070105\n",
            "Epoch: 952 Loss: 0.3309587668070105\n",
            "Epoch: 953 Loss: 0.3309587668070105\n",
            "Epoch: 954 Loss: 0.3309587668070105\n",
            "Epoch: 955 Loss: 0.3309587668070105\n",
            "Epoch: 956 Loss: 0.3309587668070105\n",
            "Epoch: 957 Loss: 0.3309587668070105\n",
            "Epoch: 958 Loss: 0.3309587668070105\n",
            "Epoch: 959 Loss: 0.3309587668070105\n",
            "Epoch: 960 Loss: 0.3309587668070105\n",
            "Epoch: 961 Loss: 0.3309587668070105\n",
            "Epoch: 962 Loss: 0.3309587668070105\n",
            "Epoch: 963 Loss: 0.3309587668070105\n",
            "Epoch: 964 Loss: 0.3309587668070105\n",
            "Epoch: 965 Loss: 0.3309587668070105\n",
            "Epoch: 966 Loss: 0.3309587668070105\n",
            "Epoch: 967 Loss: 0.3309587668070105\n",
            "Epoch: 968 Loss: 0.3309587668070105\n",
            "Epoch: 969 Loss: 0.3309587668070105\n",
            "Epoch: 970 Loss: 0.3309587668070105\n",
            "Epoch: 971 Loss: 0.3309587668070105\n",
            "Epoch: 972 Loss: 0.3309587668070105\n",
            "Epoch: 973 Loss: 0.3309587668070105\n",
            "Epoch: 974 Loss: 0.3309587668070105\n",
            "Epoch: 975 Loss: 0.3309587668070105\n",
            "Epoch: 976 Loss: 0.3309587668070105\n",
            "Epoch: 977 Loss: 0.3309587668070105\n",
            "Epoch: 978 Loss: 0.3309587668070105\n",
            "Epoch: 979 Loss: 0.3309587668070105\n",
            "Epoch: 980 Loss: 0.3309587668070105\n",
            "Epoch: 981 Loss: 0.3309587668070105\n",
            "Epoch: 982 Loss: 0.3309587668070105\n",
            "Epoch: 983 Loss: 0.3309587668070105\n",
            "Epoch: 984 Loss: 0.3309587668070105\n",
            "Epoch: 985 Loss: 0.3309587668070105\n",
            "Epoch: 986 Loss: 0.3309587668070105\n",
            "Epoch: 987 Loss: 0.3309587668070105\n",
            "Epoch: 988 Loss: 0.3309587668070105\n",
            "Epoch: 989 Loss: 0.3309587668070105\n",
            "Epoch: 990 Loss: 0.3309587668070105\n",
            "Epoch: 991 Loss: 0.3309587668070105\n",
            "Epoch: 992 Loss: 0.3309587668070105\n",
            "Epoch: 993 Loss: 0.3309587668070105\n",
            "Epoch: 994 Loss: 0.3309587668070105\n",
            "Epoch: 995 Loss: 0.3309587668070105\n",
            "Epoch: 996 Loss: 0.3309587668070105\n",
            "Epoch: 997 Loss: 0.3309587668070105\n",
            "Epoch: 998 Loss: 0.3309587668070105\n",
            "Epoch: 999 Loss: 0.3309587668070105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3ffdFwsPrgY"
      },
      "execution_count": 127,
      "outputs": []
    }
  ]
}